{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "unusual-hypothesis",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "hearing-first",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import math\n",
    "%matplotlib inline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "scientific-stuff",
   "metadata": {},
   "source": [
    "# Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "upper-queue",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path=r'C:\\Users\\91879\\Downloads\\anemia-detection-main\\database_sclere\\hbvalue.csv'   # modify the dataset_path to your own dir\n",
    "assert dataset_path!='' and dataset_path!='/path/to/dataset/', 'Please specify the dataset_path!'\n",
    "\n",
    "train_dir=dataset_path+\"training/\"\n",
    "test_dir=dataset_path+\"test/\"\n",
    "\n",
    "train_image_dir=train_dir+\"images/\"\n",
    "train_mask_dir=train_dir+\"mask/\"\n",
    "train_groundtruth_dir=train_dir+\"1st_manual/\"\n",
    "train_patch_dir=train_dir+\"patch/\"\n",
    "\n",
    "test_image_dir=test_dir+\"images/\"\n",
    "test_mask_dir=test_dir+\"mask/\"\n",
    "test_save_dir=test_dir+\"pred_result/\"\n",
    "\n",
    "train_image_path_list=glob(train_image_dir+\"*.tif\")\n",
    "test_image_path_list=glob(test_image_dir+\"*.tif\")\n",
    "\n",
    "# replaces doubles slashes with one\n",
    "train_image_path_list=[i.replace(\"\\\\\",\"/\") for i in train_image_path_list]\n",
    "test_image_path_list=[i.replace(\"\\\\\",\"/\") for i in test_image_path_list]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "addressed-clerk",
   "metadata": {},
   "source": [
    "# RGB channels of training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "derived-uncle",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for image_path in train_image_path_list[:5]:\n",
    "  image=plt.imread(image_path)\n",
    "\n",
    "  plt.figure(figsize=(15,15))\n",
    "  plt.subplot(141)\n",
    "  plt.title(\"original\")\n",
    "  plt.imshow(image)\n",
    "  plt.subplot(142)\n",
    "  plt.title(\"R-channel\")\n",
    "  plt.imshow(image[:,:,0],cmap=plt.cm.gray)\n",
    "  plt.subplot(143)\n",
    "  plt.title(\"G-channel\")\n",
    "  plt.imshow(image[:,:,1],cmap=plt.cm.gray)\n",
    "  plt.subplot(144)\n",
    "  plt.title(\"B-channel\")\n",
    "  plt.imshow(image[:,:,2],cmap=plt.cm.gray)\n",
    "  plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "potential-importance",
   "metadata": {},
   "source": [
    "# Preprocessing's functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "indoor-evans",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_normalized_single(imgs,mask):\n",
    "    imgs_normalized = np.empty(imgs.shape)\n",
    "    imgs_std = np.std(imgs)\n",
    "    imgs_mean = np.mean(imgs)\n",
    "    imgs_normalized = (imgs-imgs_mean)/imgs_std\n",
    "    for i in range(imgs.shape[2]):\n",
    "        imgs_normalized[:,:,i] = ((imgs_normalized[:,:,i] - np.min(imgs_normalized[:,:,i])) / (np.max(imgs_normalized[:,:,i])-np.min(imgs_normalized[:,:,i])))*255\n",
    "    return imgs_normalized\n",
    "\n",
    "\n",
    "# CLAHE (Contrast Limited Adaptive Histogram Equalization)\n",
    "#adaptive histogram equalization is used. In this, image is divided into small blocks called \"tiles\"\n",
    "# (tileSize is 8x8 by default in OpenCV). Then each of these blocks are histogram equalized as usual.\n",
    "#  So in a small area, histogram would confine to a small region (unless there is noise). \n",
    "# If noise is there, it will be amplified. To avoid this, contrast limiting is applied. \n",
    "# If any histogram bin is above the specified contrast limit (by default 40 in OpenCV),\n",
    "#  those pixels are clipped and distributed uniformly to other bins before applying histogram equalization.\n",
    "#  After equalization, to remove artifacts in tile borders, bilinear interpolation is applied\n",
    "def clahe_equalized_single(imgs):\n",
    "  clahe = cv2.createCLAHE(clipLimit=5.0, tileGridSize=(8,8))\n",
    "  imgs_equalized = np.empty(imgs.shape)\n",
    "  for i in range(imgs.shape[2]):\n",
    "    imgs_equalized[:,:,i] = clahe.apply(np.array(imgs[:,:,i], dtype = np.uint8))\n",
    "  return imgs_equalized\n",
    "\n",
    "\n",
    "def adjust_gamma_single(imgs, gamma=1.0):\n",
    "  invGamma = 1.0 / gamma\n",
    "  table = np.array([((i / 255.0) ** invGamma) * 255 for i in np.arange(0, 256)]).astype(\"uint8\")\n",
    "  # apply gamma correction using the lookup table\n",
    "  new_imgs = np.empty(imgs.shape)\n",
    "  for i in range(imgs.shape[2]):\n",
    "    new_imgs[:,:,i] = cv2.LUT(np.array(imgs[:,:,i], dtype = np.uint8), table)\n",
    "  return new_imgs\n",
    "\n",
    "def preprocess_single(image,mask):\n",
    "  \n",
    "  assert np.max(mask)==1\n",
    "  image=np.array(image)\n",
    "  image[:,:,0]=image[:,:,0]*mask\n",
    "  image[:,:,1]=image[:,:,1]*mask\n",
    "  image[:,:,2]=image[:,:,2]*mask\n",
    "\n",
    "  image=normal_normalized_single(image,mask)\n",
    "  image=clahe_equalized_single(image)\n",
    "  image=adjust_gamma_single(image,0.65)\n",
    "  image=image/255.0\n",
    "  return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "extreme-solomon",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "list_images=[]\n",
    "\n",
    "i=0\n",
    "for image_path in train_image_path_list:\n",
    "  image_name=image_path.split(\"/\")[-1].split(\"_\")[0]\n",
    "\n",
    "  image=plt.imread(image_path)\n",
    "\n",
    "  mask=plt.imread(train_mask_dir+image_name+\"_training_mask.gif\")\n",
    "  mask=np.where(mask>0,1,0)\n",
    "  image_original=image.copy()\n",
    "  image_processed=preprocess_single(image,mask)\n",
    "  image_processed_binary=np.asarray(0.2*image_processed[:,:,0]+0.8*image_processed[:,:,1])\n",
    "  \n",
    "  if i < 5:\n",
    "    plt.figure(figsize=(15,15))\n",
    "    plt.subplot(131)\n",
    "    plt.title(\"original\")\n",
    "    plt.imshow(image_original)\n",
    "    plt.subplot(132)\n",
    "    plt.title(\"processed\")\n",
    "    plt.imshow(image_processed)\n",
    "    plt.subplot(133)\n",
    "    plt.title(\"0.25*B+0.75*G\")\n",
    "    plt.imshow(image_processed_binary,cmap=plt.cm.gray)\n",
    "    plt.show()\n",
    "\n",
    "  image_processed_binary=np.expand_dims(image_processed_binary,0)\n",
    "  list_images.append(image_processed_binary)\n",
    "  i+=1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
